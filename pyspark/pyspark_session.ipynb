{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8204c030-239b-4eb0-8488-94478cf57cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pyspark.sql.utils import AnalysisException\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import size, lit, explode, col, round, dense_rank, rank, desc\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c034f9e-9076-4da0-b11d-f7fe9fad04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_file(file):\n",
    "    print(f'\\n\\x1b[1;33;40mRead {file} Json Data...\\x1b[0m\\n')\n",
    "    json_file = pyspark_session.read.option(\"multiline\", \"true\").json(file)\n",
    "    return json_file\n",
    "\n",
    "def get_csv_file(file, sep=None):\n",
    "    print(f'\\n\\x1b[1;33;40mRead {file} Csv Data...\\x1b[0m\\n')\n",
    "    csv_file  = pyspark_session.read.csv(file, header = True, sep = sep)\n",
    "    return csv_file\n",
    "\n",
    "\n",
    "def first_dataframe(file):\n",
    "    data = get_json_file(file)\n",
    "    rdd  = data.rdd.map(lambda x: (x[0][\"site_id\"], x[0][\"id\"] , x[0][\"nickname\"] , x[0][\"points\"]))  \n",
    "    data = rdd.toDF([\"siteId\", \"sellerId\", \"sellerNickname\", \"sellerPoints\"])\n",
    "    first_save_file(data)\n",
    "    return data\n",
    "    \n",
    "def first_save_file(data):\n",
    "    archivos = ['positivo', 'cero', 'negativo']\n",
    "    for archivo in archivos:\n",
    "        folder   = f\"MPE/2022/10/29/{archivo}\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        file_csv = f\"MPE/2022/10/29/{archivo}/{archivo}.csv\"\n",
    "        if archivo == 'positivo':\n",
    "            dataframe = data.filter((data.sellerPoints > 0))\n",
    "        if archivo == 'cero':\n",
    "            dataframe = data.filter((data.sellerPoints == 0))\n",
    "        if archivo == 'negativo':\n",
    "            dataframe = data.filter((data.sellerPoints < 0))\n",
    "        dataframe.toPandas().to_csv(file_csv, index=False)\n",
    "\n",
    "\n",
    "def second_dataframe(file, columns=['rowId','itemId', 'soldQuantity', 'availableQuantity']):\n",
    "    data = get_json_file(file)\n",
    "    longitud = data.select(size(data.results)).collect()[0][0]\n",
    "    total_values = []\n",
    "    for i in range(0, longitud):\n",
    "        count = i+1\n",
    "        rdd = data.rdd.map(lambda x: (count, \\\n",
    "                                      x[\"results\"][i]['id'], \\\n",
    "                                      x[\"results\"][i]['sold_quantity'], \\\n",
    "                                      x[\"results\"][i]['available_quantity'])) \n",
    "        values = rdd.collect()[0]\n",
    "        total_values.append(values)\n",
    "    data = pyspark_session.createDataFrame(data=total_values, schema = columns)\n",
    "    return data\n",
    "\n",
    "\n",
    "def third_dataframe(data_2, file):\n",
    "    data_3 = get_csv_file(file)\n",
    "    join_data = data_2.join(data_3, data_2.itemId ==  data_3.itemId,\"inner\") \\\n",
    "                     .select(data_2.itemId, data_2.soldQuantity,data_3.visits) \\\n",
    "                     .filter((data_2.soldQuantity > 0))\n",
    "    return join_data\n",
    "\n",
    "\n",
    "def forth_dataframe(data_3):\n",
    "    data = data_3.withColumn(\"conversionRate\", round(data_3.soldQuantity / data_3.visits,4)) \\\n",
    "               .sort(col(\"conversionRate\").desc()) \\\n",
    "               .withColumn(\"conversionRanking\", dense_rank().over(Window.orderBy(desc('conversionRate'))))\n",
    "    return data\n",
    "\n",
    "\n",
    "def fifth_dataframe(data_2):\n",
    "    total_available = data_2.agg({'availableQuantity': 'sum'}).collect()[0][0]\n",
    "    data = data_2.withColumn(\"stockPercentage\", round((data_2.availableQuantity / total_available) * 100 , 2)) \\\n",
    "                .sort(col(\"stockPercentage\").desc()) \\\n",
    "                .select(\"itemId\",\"availableQuantity\",\"stockPercentage\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8cfa95e-5a9a-4822-a818-9ec12a629e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_session = SparkSession \\\n",
    "                .builder \\\n",
    "                .appName(\"spark_session\") \\\n",
    "                .config('spark.driver.memory', '6g') \\\n",
    "                .getOrCreate()\n",
    "\n",
    "sparkContext = pyspark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7803e715-961a-46a9-a502-3b30d4223da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;33;40mRead Json Data...\u001b[0m\n",
      "\n",
      "+------+---------+---------------+------------+\n",
      "|siteId| sellerId| sellerNickname|sellerPoints|\n",
      "+------+---------+---------------+------------+\n",
      "|   MPE|298734964| MARIELATAQUIRE|           2|\n",
      "|   MPE|183049329|    MURO8709951|          -3|\n",
      "|   MPE| 94592189|     ILLARYPERU|          -2|\n",
      "|   MPE|520133997|ISABELLADELPOZO|           1|\n",
      "|   MPE|684964436|    PHMO1747353|           0|\n",
      "+------+---------+---------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1 = first_dataframe(\"jsonfiles/Sellers.json\")\n",
    "df_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d44410f-809b-4c23-b92a-00e69242db86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;33;40mRead Json Data...\u001b[0m\n",
      "\n",
      "+-----+------------+------------+-----------------+\n",
      "|rowId|      itemId|soldQuantity|availableQuantity|\n",
      "+-----+------------+------------+-----------------+\n",
      "|    1|MPE433108265|           6|                9|\n",
      "|    2|MPE434382765|           6|                3|\n",
      "|    3|MPE433853177|           3|               17|\n",
      "|    4|MPE419883282|          15|               18|\n",
      "|    5|MPE431714651|          15|                1|\n",
      "+-----+------------+------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_2 = second_dataframe(\"jsonfiles/MPE1004.json\")\n",
    "df_2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d257bd-46b0-4bf6-ae16-944075bc9bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;33;40mRead Csv Data...\u001b[0m\n",
      "\n",
      "+------------+------------+------+\n",
      "|      itemId|soldQuantity|visits|\n",
      "+------------+------------+------+\n",
      "|MPE433108265|           6|   203|\n",
      "|MPE434382765|           6|   170|\n",
      "|MPE433853177|           3|  1034|\n",
      "|MPE419883282|          15|  1772|\n",
      "|MPE431714651|          15|    33|\n",
      "+------------+------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_3 = third_dataframe(df_2, 'csvfiles/visits.csv')\n",
    "df_3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f88c18-1179-4727-993e-dccfb32457bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------+--------------+-----------------+\n",
      "|      itemId|soldQuantity|visits|conversionRate|conversionRanking|\n",
      "+------------+------------+------+--------------+-----------------+\n",
      "|MPE431714651|          15|    33|        0.4545|                1|\n",
      "|MPE432291284|           2|     6|        0.3333|                2|\n",
      "|MPE427140390|          10|    81|        0.1235|                3|\n",
      "|MPE432439269|           2|    42|        0.0476|                4|\n",
      "|MPE434382765|           6|   170|        0.0353|                5|\n",
      "+------------+------------+------+--------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_4 = forth_dataframe(df_3)\n",
    "df_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c00f0297-bb68-4176-a6d5-6a0a26fccae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+---------------+\n",
      "|      itemId|availableQuantity|stockPercentage|\n",
      "+------------+-----------------+---------------+\n",
      "|MPE433046443|              999|           70.3|\n",
      "|MPE438492919|              100|           7.04|\n",
      "|MPE436649728|              100|           7.04|\n",
      "|MPE429448587|               50|           3.52|\n",
      "|MPE431446248|               23|           1.62|\n",
      "+------------+-----------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_5 = fifth_dataframe(df_2)\n",
    "df_5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48da6839-d366-476b-bcd1-b67988291519",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
